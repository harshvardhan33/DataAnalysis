{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection using Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:/Python DataScience/Feature Selection/santander-train.csv\",nrows=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['TARGET'],axis=1)\n",
    "y = df['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train ,X_test ,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_filter = VarianceThreshold(threshold=0)\n",
    "constant_filter.fit(X_train)\n",
    "X_train_filter = constant_filter.transform(X_train)\n",
    "X_test_filter = constant_filter.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filter.shape,X_test_filter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quasi_constant_filter = VarianceThreshold(threshold=0.01)\n",
    "X_train_quasifilter = quasi_constant_filter.fit_transform(X_train_filter)\n",
    "X_test_quasifilter = quasi_constant_filter.transform(X_test_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_quasifilter.shape,X_test_quasifilter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_T = X_train_quasifilter.T\n",
    "X_test_T = X_test_quasifilter.T\n",
    "X_train_T = pd.DataFrame(X_train_T)\n",
    "X_test_T = pd.DataFrame(X_test_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_T.shape , X_test_T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_features = X_train_T.duplicated()\n",
    "non_duplicated_features = [not i for i in duplicated_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unique = X_train_T[non_duplicated_features].T\n",
    "X_test_unique = X_test_T[non_duplicated_features].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unique.shape,X_test_unique.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use of Pearson Correlation Coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take correlation factor as 85%.\n",
    "If two features are more then 85% correlated we drop one of the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = X_train_unique.corr()\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(corr_matirx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting out the list of all correlated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr(data,threshold):\n",
    "    corr_col = set()\n",
    "    corr_mat = data.corr()\n",
    "    for i in range(len(corr_mat.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_mat.iloc[i,j])>threshold:\n",
    "                col_name = corr_mat.columns[i]\n",
    "                corr_col.add(col_name)\n",
    "                \n",
    "    return list(corr_col)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_list = get_corr(X_train_unique,0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_uncorr = X_train_unique.drop(corr_list,axis=1)\n",
    "X_test_uncorr = X_test_unique.drop(corr_list,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_uncorr.shape,X_test_uncorr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_randomForest(X_train,X_test,y_train,y_test):\n",
    "    clf = RandomForestClassifier(n_estimators=100,random_state=0,n_jobs=-1)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Accuracy is : \",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :  0.95875\n",
      "Wall time: 1.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "run_randomForest(X_train_uncorr,X_test_uncorr,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :  0.9585\n",
      "Wall time: 3.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "run_randomForest(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance and Feature Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "      <th>237</th>\n",
       "      <th>238</th>\n",
       "      <th>239</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025277</td>\n",
       "      <td>-0.001942</td>\n",
       "      <td>0.003594</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>-0.001697</td>\n",
       "      <td>-0.015882</td>\n",
       "      <td>-0.019807</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>-0.000588</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001337</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>-0.008500</td>\n",
       "      <td>0.006554</td>\n",
       "      <td>0.005907</td>\n",
       "      <td>0.008825</td>\n",
       "      <td>-0.009174</td>\n",
       "      <td>0.012031</td>\n",
       "      <td>0.012128</td>\n",
       "      <td>0.006612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.025277</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007647</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>0.008981</td>\n",
       "      <td>0.009232</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.000415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.001942</td>\n",
       "      <td>-0.007647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.030919</td>\n",
       "      <td>0.106245</td>\n",
       "      <td>0.109140</td>\n",
       "      <td>0.048524</td>\n",
       "      <td>0.055708</td>\n",
       "      <td>0.004040</td>\n",
       "      <td>0.005796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025522</td>\n",
       "      <td>0.020168</td>\n",
       "      <td>0.011550</td>\n",
       "      <td>0.019325</td>\n",
       "      <td>0.019527</td>\n",
       "      <td>0.041321</td>\n",
       "      <td>0.016172</td>\n",
       "      <td>0.043577</td>\n",
       "      <td>0.044281</td>\n",
       "      <td>-0.000810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003594</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>0.030919</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.029418</td>\n",
       "      <td>0.024905</td>\n",
       "      <td>0.014513</td>\n",
       "      <td>0.013857</td>\n",
       "      <td>-0.000613</td>\n",
       "      <td>-0.000691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014032</td>\n",
       "      <td>-0.000583</td>\n",
       "      <td>-0.000337</td>\n",
       "      <td>-0.000548</td>\n",
       "      <td>-0.000561</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>-0.000577</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.008981</td>\n",
       "      <td>0.106245</td>\n",
       "      <td>0.029418</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888789</td>\n",
       "      <td>0.381632</td>\n",
       "      <td>0.341266</td>\n",
       "      <td>0.012927</td>\n",
       "      <td>0.019674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002328</td>\n",
       "      <td>0.016743</td>\n",
       "      <td>-0.001662</td>\n",
       "      <td>0.020509</td>\n",
       "      <td>0.021276</td>\n",
       "      <td>-0.001905</td>\n",
       "      <td>-0.000635</td>\n",
       "      <td>-0.002552</td>\n",
       "      <td>-0.002736</td>\n",
       "      <td>0.003656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>0.008825</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.041321</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>-0.001905</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>-0.000818</td>\n",
       "      <td>-0.000866</td>\n",
       "      <td>-0.000309</td>\n",
       "      <td>-0.000349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012705</td>\n",
       "      <td>0.021540</td>\n",
       "      <td>-0.000170</td>\n",
       "      <td>0.032162</td>\n",
       "      <td>0.030087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.329805</td>\n",
       "      <td>0.935317</td>\n",
       "      <td>0.919036</td>\n",
       "      <td>0.011106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>-0.009174</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.016172</td>\n",
       "      <td>-0.000577</td>\n",
       "      <td>-0.000635</td>\n",
       "      <td>0.007096</td>\n",
       "      <td>-0.000515</td>\n",
       "      <td>-0.000545</td>\n",
       "      <td>-0.000195</td>\n",
       "      <td>-0.000220</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>-0.000185</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>0.329805</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.127224</td>\n",
       "      <td>0.140902</td>\n",
       "      <td>0.011807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>0.012031</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>0.043577</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>-0.002552</td>\n",
       "      <td>-0.001672</td>\n",
       "      <td>-0.000779</td>\n",
       "      <td>-0.000825</td>\n",
       "      <td>-0.000295</td>\n",
       "      <td>-0.000332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027515</td>\n",
       "      <td>0.012393</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>0.018565</td>\n",
       "      <td>0.017358</td>\n",
       "      <td>0.935317</td>\n",
       "      <td>0.127224</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993536</td>\n",
       "      <td>0.008604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.012128</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.044281</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>-0.002736</td>\n",
       "      <td>-0.001844</td>\n",
       "      <td>-0.000839</td>\n",
       "      <td>-0.000888</td>\n",
       "      <td>-0.000317</td>\n",
       "      <td>-0.000358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023072</td>\n",
       "      <td>0.014523</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.021742</td>\n",
       "      <td>0.020331</td>\n",
       "      <td>0.919036</td>\n",
       "      <td>0.140902</td>\n",
       "      <td>0.993536</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0.006612</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>-0.000810</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.003656</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>0.004448</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>-0.000739</td>\n",
       "      <td>-0.000811</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003399</td>\n",
       "      <td>-0.000773</td>\n",
       "      <td>-0.000402</td>\n",
       "      <td>-0.000525</td>\n",
       "      <td>-0.000589</td>\n",
       "      <td>0.011106</td>\n",
       "      <td>0.011807</td>\n",
       "      <td>0.008604</td>\n",
       "      <td>0.009136</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>227 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    1.000000 -0.025277 -0.001942  0.003594  0.004054 -0.001697 -0.015882   \n",
       "1   -0.025277  1.000000 -0.007647  0.001819  0.008981  0.009232  0.001638   \n",
       "2   -0.001942 -0.007647  1.000000  0.030919  0.106245  0.109140  0.048524   \n",
       "3    0.003594  0.001819  0.030919  1.000000  0.029418  0.024905  0.014513   \n",
       "4    0.004054  0.008981  0.106245  0.029418  1.000000  0.888789  0.381632   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "240  0.008825  0.000922  0.041321  0.000541 -0.001905  0.000871 -0.000818   \n",
       "241 -0.009174  0.000598  0.016172 -0.000577 -0.000635  0.007096 -0.000515   \n",
       "242  0.012031  0.000875  0.043577  0.000231 -0.002552 -0.001672 -0.000779   \n",
       "243  0.012128  0.000942  0.044281  0.000235 -0.002736 -0.001844 -0.000839   \n",
       "244  0.006612  0.000415 -0.000810  0.000966  0.003656  0.002257  0.004448   \n",
       "\n",
       "          7         8         9    ...       235       236       237  \\\n",
       "0   -0.019807  0.000956 -0.000588  ... -0.001337  0.002051 -0.008500   \n",
       "1    0.001746  0.000614  0.000695  ...  0.000544  0.000586  0.000337   \n",
       "2    0.055708  0.004040  0.005796  ...  0.025522  0.020168  0.011550   \n",
       "3    0.013857 -0.000613 -0.000691  ...  0.014032 -0.000583 -0.000337   \n",
       "4    0.341266  0.012927  0.019674  ...  0.002328  0.016743 -0.001662   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "240 -0.000866 -0.000309 -0.000349  ...  0.012705  0.021540 -0.000170   \n",
       "241 -0.000545 -0.000195 -0.000220  ... -0.000173 -0.000185 -0.000107   \n",
       "242 -0.000825 -0.000295 -0.000332  ...  0.027515  0.012393 -0.000162   \n",
       "243 -0.000888 -0.000317 -0.000358  ...  0.023072  0.014523 -0.000174   \n",
       "244  0.002427 -0.000739 -0.000811  ... -0.003399 -0.000773 -0.000402   \n",
       "\n",
       "          238       239       240       241       242       243       244  \n",
       "0    0.006554  0.005907  0.008825 -0.009174  0.012031  0.012128  0.006612  \n",
       "1    0.000550  0.000563  0.000922  0.000598  0.000875  0.000942  0.000415  \n",
       "2    0.019325  0.019527  0.041321  0.016172  0.043577  0.044281 -0.000810  \n",
       "3   -0.000548 -0.000561  0.000541 -0.000577  0.000231  0.000235  0.000966  \n",
       "4    0.020509  0.021276 -0.001905 -0.000635 -0.002552 -0.002736  0.003656  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "240  0.032162  0.030087  1.000000  0.329805  0.935317  0.919036  0.011106  \n",
       "241 -0.000174 -0.000178  0.329805  1.000000  0.127224  0.140902  0.011807  \n",
       "242  0.018565  0.017358  0.935317  0.127224  1.000000  0.993536  0.008604  \n",
       "243  0.021742  0.020331  0.919036  0.140902  0.993536  1.000000  0.009136  \n",
       "244 -0.000525 -0.000589  0.011106  0.011807  0.008604  0.009136  1.000000  \n",
       "\n",
       "[227 rows x 227 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data = corr_matrix.abs().stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51529"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corr_data) # all the feature are stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0      1.000000\n",
       "     1      0.025277\n",
       "     2      0.001942\n",
       "     3      0.003594\n",
       "     4      0.004054\n",
       "              ...   \n",
       "244  240    0.011106\n",
       "     241    0.011807\n",
       "     242    0.008604\n",
       "     243    0.009136\n",
       "     244    1.000000\n",
       "Length: 51529, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data = corr_data.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29   58     1.000000e+00\n",
       "58   29     1.000000e+00\n",
       "134  158    1.000000e+00\n",
       "158  134    1.000000e+00\n",
       "182  182    1.000000e+00\n",
       "                ...     \n",
       "229  111    1.934954e-06\n",
       "231  150    6.044672e-07\n",
       "150  231    6.044672e-07\n",
       "231  123    3.966696e-07\n",
       "123  231    3.966696e-07\n",
       "Length: 51529, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data = corr_data[corr_data>0.85]\n",
    "corr_data = corr_data[corr_data<1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143  135    1.000000\n",
       "135  143    1.000000\n",
       "136  128    1.000000\n",
       "128  136    1.000000\n",
       "31   62     1.000000\n",
       "              ...   \n",
       "67   66     0.851384\n",
       "61   28     0.851022\n",
       "28   61     0.851022\n",
       "72   35     0.850893\n",
       "35   72     0.850893\n",
       "Length: 534, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data = pd.DataFrame(corr_data).reset_index()\n",
    "corr_data.columns = ['Features1','Features2','corr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making group of correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_feature_list = []\n",
    "correlated_groups_list = []\n",
    "\n",
    "for feature in corr_data.Features1.unique():\n",
    "    if feature not in group_feature_list:\n",
    "        corr_block = corr_data[corr_data.Features1 == feature]\n",
    "        group_feature_list = group_feature_list + list(corr_block.Features2.unique())+[feature]\n",
    "        correlated_groups_list.append(corr_block)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(correlated_groups_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Features1  Features2  corr\n",
      "0        143        135   1.0\n",
      "     Features1  Features2      corr\n",
      "2          136        128  1.000000\n",
      "197        136        169  0.959468\n",
      "   Features1  Features2  corr\n",
      "4         31         62   1.0\n",
      "   Features1  Features2  corr\n",
      "6         20         47   1.0\n",
      "     Features1  Features2      corr\n",
      "8           52         23  1.000000\n",
      "297         52         24  0.927683\n",
      "299         52         53  0.927683\n",
      "448         52         21  0.877297\n",
      "505         52        183  0.860163\n",
      "     Features1  Features2      corr\n",
      "12          33         69  1.000000\n",
      "224         33         32  0.947113\n",
      "228         33         68  0.946571\n",
      "322         33         26  0.917665\n",
      "337         33         55  0.914178\n",
      "422         33        184  0.884383\n",
      "    Features1  Features2  corr\n",
      "14        157        133   1.0\n",
      "    Features1  Features2      corr\n",
      "16        237        149  1.000000\n",
      "26        237        148  0.999929\n",
      "    Features1  Features2  corr\n",
      "18        154        132   1.0\n",
      "     Features1  Features2      corr\n",
      "20         146        230  0.999997\n",
      "36         146        229  0.999778\n",
      "59         146        231  0.997052\n",
      "68         146        232  0.996772\n",
      "76         146        113  0.996424\n",
      "89         146        120  0.993307\n",
      "245        146        170  0.944314\n",
      "     Features1  Features2      corr\n",
      "22         238        122  0.999945\n",
      "49         238        239  0.998497\n",
      "264        238        236  0.938668\n",
      "    Features1  Features2      corr\n",
      "34         82         78  0.999859\n",
      "     Features1  Features2      corr\n",
      "40         108        115  0.999478\n",
      "97         108        219  0.992870\n",
      "115        108        125  0.987333\n",
      "142        108        220  0.982474\n",
      "280        108        217  0.933815\n",
      "     Features1  Features2      corr\n",
      "46         199        197  0.998753\n",
      "362        199        196  0.905699\n",
      "371        199        198  0.904341\n",
      "     Features1  Features2      corr\n",
      "50         181        208  0.997718\n",
      "345        181        205  0.911453\n",
      "467        181        207  0.871801\n",
      "     Features1  Features2      corr\n",
      "72          17         14  0.996739\n",
      "396         17         16  0.890442\n",
      "408         17         13  0.888669\n",
      "     Features1  Features2      corr\n",
      "86         242        243  0.993536\n",
      "122        242        126  0.986744\n",
      "276        242        240  0.935317\n",
      "     Features1  Features2      corr\n",
      "92          28         57  0.993186\n",
      "124         28         58  0.986371\n",
      "126         28         29  0.986371\n",
      "185         28        185  0.964067\n",
      "381         28         27  0.901032\n",
      "399         28         30  0.889321\n",
      "531         28         61  0.851022\n",
      "     Features1  Features2      corr\n",
      "94          51         22  0.992882\n",
      "385         51        182  0.899063\n",
      "     Features1  Features2      corr\n",
      "100         44         46  0.990593\n",
      "377         44         98  0.902736\n",
      "410         44         95  0.888337\n",
      "     Features1  Features2      corr\n",
      "102         77         81  0.989793\n",
      "461         77         80  0.874240\n",
      "517         77         84  0.858529\n",
      "     Features1  Features2      corr\n",
      "104        109        223  0.989341\n",
      "151        109        224  0.980951\n",
      "356        109        221  0.907987\n",
      "413        109        111  0.887721\n",
      "     Features1  Features2      corr\n",
      "112          9          8  0.988256\n",
      "417          9        193  0.886955\n",
      "444          9        192  0.878045\n",
      "     Features1  Features2      corr\n",
      "116        227        228  0.987304\n",
      "188        227        225  0.962657\n",
      "     Features1  Features2      corr\n",
      "118        116        117  0.987013\n",
      "     Features1  Features2      corr\n",
      "128         91         49  0.985951\n",
      "     Features1  Features2      corr\n",
      "130         54         25  0.985875\n",
      "419         54        100  0.886309\n",
      "     Features1  Features2      corr\n",
      "134         76         75  0.984751\n",
      "353         76         74  0.908497\n",
      "477         76        191  0.870551\n",
      "522         76        190  0.857717\n",
      "     Features1  Features2      corr\n",
      "136         38         35  0.984077\n",
      "261         38         34  0.940390\n",
      "306         38         36  0.922699\n",
      "496         38         72  0.864661\n",
      "     Features1  Features2      corr\n",
      "138         18         15  0.983164\n",
      "465         18         16  0.872133\n",
      "470         18         13  0.870936\n",
      "     Features1  Features2      corr\n",
      "140        215        107  0.983156\n",
      "146        215        216  0.981815\n",
      "     Features1  Features2      corr\n",
      "161         56         61  0.976942\n",
      "187         56         27  0.962726\n",
      "211         56         30  0.953194\n",
      "     Features1  Features2      corr\n",
      "164        162        163  0.975002\n",
      "288        162        161  0.930635\n",
      "369        162        164  0.904702\n",
      "463        162         41  0.874083\n",
      "     Features1  Features2      corr\n",
      "166        102        103  0.974341\n",
      "     Features1  Features2      corr\n",
      "168         83         79  0.973140\n",
      "263         83        188  0.938960\n",
      "273         83         84  0.936080\n",
      "315         83        194  0.919405\n",
      "351         83         80  0.910385\n",
      "518         83        189  0.858484\n",
      "     Features1  Features2      corr\n",
      "174         70         72  0.972088\n",
      "500         70         35  0.862850\n",
      "     Features1  Features2      corr\n",
      "180         59         60  0.968504\n",
      "     Features1  Features2      corr\n",
      "207        195        189  0.956666\n",
      "313        195         80  0.920961\n",
      "330        195        194  0.916442\n",
      "378        195         84  0.902276\n",
      "428        195        188  0.882312\n",
      "509        195         79  0.859806\n",
      "     Features1  Features2      corr\n",
      "216        235        234  0.950232\n",
      "349        235        106  0.911179\n",
      "     Features1  Features2      corr\n",
      "220         10        104  0.948845\n",
      "     Features1  Features2      corr\n",
      "234        180        179  0.945288\n",
      "     Features1  Features2      corr\n",
      "236        241        151  0.944812\n",
      "     Features1  Features2      corr\n",
      "243         42         41  0.944451\n",
      "415         42        161  0.887059\n",
      "503         42        164  0.861507\n",
      "     Features1  Features2      corr\n",
      "248         12          5  0.943622\n",
      "434         12         11  0.881673\n",
      "     Features1  Features2      corr\n",
      "266          4         11  0.938409\n",
      "402          4          5  0.888789\n",
      "     Features1  Features2      corr\n",
      "274         93         92  0.935867\n",
      "     Features1  Features2      corr\n",
      "290         89        121  0.928898\n",
      "     Features1  Features2   corr\n",
      "304         88         87  0.924\n",
      "     Features1  Features2      corr\n",
      "318        174        204  0.918533\n",
      "     Features1  Features2      corr\n",
      "333         50         21  0.916137\n",
      "     Features1  Features2      corr\n",
      "354          6          7  0.908158\n",
      "     Features1  Features2      corr\n",
      "372         64         65  0.904095\n",
      "488         64         87  0.866430\n",
      "     Features1  Features2      corr\n",
      "374        101         86  0.903641\n",
      "394        101         40  0.892951\n",
      "     Features1  Features2     corr\n",
      "390        131        153  0.89633\n",
      "     Features1  Features2      corr\n",
      "525        173        151  0.854991\n",
      "     Features1  Features2      corr\n",
      "528         66         67  0.851384\n"
     ]
    }
   ],
   "source": [
    "for feature in correlated_groups_list:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance using Tree Classifier\n",
    "### Extracting the most important feature in each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intitially we create empty list for storing important features\n",
    "important_features = []\n",
    "\n",
    "# In each group we are getting the most important feature\n",
    "\n",
    "for group in correlated_groups_list:\n",
    "    # In each group we are gathering unique features\n",
    "    features = list(group.Features1.unique())+list(group.Features2.unique())\n",
    "    \n",
    "    # USE of random forest to estimate the importance\n",
    "    rf = RandomForestClassifier(n_estimators=100,random_state=0)\n",
    "    rf.fit(X_train_unique[features],y_train)\n",
    "    \n",
    "    #creating a dataframe for important features along with their importance\n",
    "    important = pd.concat([pd.Series(features),pd.Series(rf.feature_importances_)],axis=1)\n",
    "    important.columns = [\"Features\",'importance']\n",
    "    \n",
    "    # sort the columns by highest importance \n",
    "    important.sort_values(by='importance',ascending = False,inplace=True)\n",
    "    \n",
    "    # from each group taking out the top most column\n",
    "    feat = important.iloc[0]\n",
    "    important_features.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features = pd.DataFrame(important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135.0</td>\n",
       "      <td>0.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.563757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.0</td>\n",
       "      <td>0.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>183.0</td>\n",
       "      <td>0.285817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Features  importance\n",
       "0     135.0    0.510000\n",
       "1     128.0    0.563757\n",
       "2      62.0    0.510000\n",
       "3      47.0    0.510000\n",
       "4     183.0    0.285817"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_consider = set(important_features['Features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_discard = list(set(corr_list)-set(feature_consider))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_discard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discarding the features that are not important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_grouped_uncorr = X_train_unique.drop(feature_discard,axis=1)\n",
    "X_test_grouped_uncorr = X_test_unique.drop(feature_discard,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 140), (4000, 140))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_grouped_uncorr.shape,X_test_grouped_uncorr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :  0.95775\n",
      "Wall time: 1.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "run_randomForest(X_train_grouped_uncorr,X_test_grouped_uncorr,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
